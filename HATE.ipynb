{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lightning-nub/hate_speech/blob/main/HATE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hueHX-39UT4P"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q\n",
        "! pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSZDBXPVU397"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "from nltk.util import pr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "data = pd.read_csv(\"twitter.csv\")\n",
        "data[\"labels\"] = data[\"class\"].map({0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"No Hate and Offensive\"})\n",
        "data = data[[\"tweet\", \"labels\"]]\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))\n",
        "\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text=\" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text=\" \".join(text)\n",
        "    return text\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(clean)\n",
        "#print(data.head())\n",
        "\n",
        "x = np.array(data[\"tweet\"])\n",
        "y = np.array(data[\"labels\"])\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x) # Fit the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_test,y_test)\n",
        "\n",
        "def hate_speech_detection():\n",
        "    import streamlit as st\n",
        "    st.title(\"Hate Speech Detection\")\n",
        "    user = st.text_area(\"Enter any Tweet: \")\n",
        "    if len(user) < 1:\n",
        "        st.write(\"  \")\n",
        "    else:\n",
        "        sample = user\n",
        "        data = cv.transform([sample]).toarray()\n",
        "        a = clf.predict(data)\n",
        "        st.title(a)\n",
        "hate_speech_detection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "waKnQQHkVENb"
      },
      "outputs": [],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R1quykJrjhn"
      },
      "outputs": [],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CPijdW1rjxM"
      },
      "outputs": [],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}